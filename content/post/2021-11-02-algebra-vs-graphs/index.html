---
title: do-calculus to Specify causality
author: Ted Farley
date: '2021-11-02'
slug: []
categories: []
tags: [causal-inference, ols]
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="entry-level-analyst-puzzle" class="section level1">
<h1>Entry-level analyst puzzle</h1>
<p>Last week <a href="https://twitter.com/bennpeifert">Benn Eifert</a> (a quantitative-finance guy<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>) posted this puzzle on twitter last week. The puzzle was intriguing to me but it would have taken me a few weeks to solve on my own, luckily Benn posted the answer yesterday! Below is the puzzle &amp; answer along with Benn’s interpretation. I then split hairs over specifying correlation/causation and suggest using ‘do-calculus’ to be more explicit about causal relationships.</p>
<div id="the-prompt" class="section level2">
<h2>The prompt</h2>
<blockquote>
<p>Saturday morning entry-level analyst interview question.<br />
The variable Y is caused by Z, plus some i.i.d. noise e:</p>
</blockquote>
<p><span class="math display">\[\begin{align*}
Y_{t} &amp; = a_{0} + a_{1}Z_{t} + e_{t} \\
\end{align*}\]</span></p>
<blockquote>
<p>But Z also happens to be correlated with some other variable X:</p>
</blockquote>
<p><span class="math display">\[\begin{align*}
X_{t} &amp; = b_{0} + b_{1}Z_{t} + f_{t}
\end{align*}\]</span></p>
<blockquote>
<p>You’re an internet troll so you ignore Z and just estimate the univariate relationship via ordinary least squares regression:</p>
</blockquote>
<p><span class="math display">\[\begin{align*}
Y_{t} &amp; = c_{0} + c_{1}X_{t} + g_{t}
\end{align*}\]</span></p>
<blockquote>
<p>Derive the estimate of c1 that you will obtain via OLS and explain.</p>
</blockquote>
</div>
<div id="the-answer" class="section level2">
<h2>The answer</h2>
<p><span class="math display">\[\begin{align*}
\hat{c}_{1} &amp; = \frac{\hat{cov}(Y_{t}, X_{t})}{\hat{var}(X_{t})}
\end{align*}\]</span></p>
<p>substitute <span class="math inline">\(RHS\)</span> of <span class="math inline">\(Y_{t}\)</span> and <span class="math inline">\(X_{t}\)</span> in:</p>
<p></br></p>
<p><span class="math display">\[\begin{align*}
  \hat{c}_{1} &amp; = \frac{\hat{cov}(a_{0} + a_{1}Z_{t} + e_{t}, b_{0} + b_{1}Z_{t} + f_{t})}{\hat{var}(X_{t})}  
\end{align*}\]</span></p>
<p>additive terms can be ignored (intercept estimates and error terms):</p>
<p><span class="math display">\[\begin{align*}
  \hat{c}_{1} &amp; = \frac{\hat{cov}(a_{1}Z_{t},b_{1}Z_{t})}{\hat{var}(X_{t})}  
\end{align*}\]</span></p>
<p>pull out constant terms:</p>
<p><span class="math display">\[\begin{align*}
  \hat{c}_{1} &amp; = b_{1} * a_{1}\frac{\hat{cov}(Z_{t}, Z_{t})}{\hat{var}(X_{t})} 
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*} 
   \hat{c}_{1} &amp; = b_{1} * a_{1}\frac{\hat{var}(Z_{t})}{\hat{var}(X_{t})}
\end{align*}\]</span></p>
</div>
<div id="benns-interpretation" class="section level2">
<h2>Benn’s interpretation</h2>
<blockquote>
<p>So we infer a (false) relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>, proportional to the (true) relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span>, and the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>.</p>
</blockquote>
</div>
<div id="causal-models-can-be-helpful" class="section level2">
<h2>Causal Model’s can be helpful!</h2>
<p>I think the main purpose of the question was in deriving an OLS estimate for <span class="math inline">\(Y(X)\)</span> given the relationships of <span class="math inline">\(X(Z)\)</span> and <span class="math inline">\(Y(Z)\)</span> which is shown in the algebra above. To be clear I would have failed miserably at deriving this estimate, but I enjoyed following along with the answer.</p>
<p>It is true that no matter what, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent of each other when you condition on <span class="math inline">\(Z\)</span>.</p>
<p><span class="math display">\[\begin{align*}
  E[Y | Z, X] = E[Y | Z]
\end{align*}\]</span></p>
<p>However, I think there were some important ambiguities in the prompt and Benn’s interpretation of the estimate. Primarily, Benn posits that the relationship between <span class="math inline">\(X \sim Y\)</span> is ‘false’. I think what he means here is that the OLS estimate, interpreted as a measure of causality is spurious in this case. Benn says, <em>“Z also happens to be correlated with some other variable X”</em>. However, the causal relationship between <span class="math inline">\(X \sim Y\)</span> is only ‘false’ if we specify that the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> is <span class="math inline">\(Z \rightarrow X\)</span> (<span class="math inline">\(Z\)</span> causes <span class="math inline">\(X\)</span>).</p>
</div>
<div id="specifying-causality-using-do-calculus" class="section level2">
<h2>Specifying Causality using ‘do-calculus’</h2>
<p>Using <em>do-calculus</em> allows us to ‘play-god’. In the ‘analyst puzzle’ we ask: “if you alter <span class="math inline">\(X\)</span> and nothing else, would <span class="math inline">\(Y\)</span> change”? If <span class="math inline">\(Z \rightarrow X\)</span> then we would expect the following to hold:</p>
<p><span class="math display">\[\begin{align*}
  E[Y | do(X = x_{0})] = E[Y | do(X = x_{1})]
\end{align*}\]</span></p>
<p>alternatively, if <span class="math inline">\(X \rightarrow Z\)</span> then we would expect:</p>
<p><span class="math display">\[\begin{align*}
E[Y | do(X = x_{0})] \neq E[Y | do(X = x_{1})]
\end{align*}\]</span></p>
<p><em>do-calculus</em> seems really pointless when working with observational data mostly because non-one will ever get to <em>actually</em> play god. Where it’s most useful for me (a causal-inference hobbyist) is using it to specify exactly what I mean by “X causes Y”, conditional dependence is not enough to do this. For example it is tempting to say that because:</p>
<p><span class="math display">\[\begin{align*}
  E[Y | Z, X] = E[Y | Z]
\end{align*}\]</span></p>
<p>there is no causal relationship between <span class="math inline">\(X \sim Y\)</span>. However, conditioning on <span class="math inline">\(Y\)</span> may be masking the true causal relationship. Determining causality is really tricky business, counter-intuitive relationships are everywhere and using the wrong conditional dependencies can lead you down the wrong path. This, I think, is a good reason to use causal models that are seperate (and come before) your statistical models.</p>
<hr />
</div>
</div>
<div id="the-original-tweets" class="section level1">
<h1>The original tweets</h1>
<div id="prompt" class="section level2">
<h2>prompt:</h2>
<p></br></p>
<p>{{% tweet "1454494974238625795" %}}</p>
</div>
<div id="answer" class="section level2">
<h2>answer:</h2>
<p></br></p>
<p>{{% tweet "1454494972556701699" %}}</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>he also writes <a href="https://twitter.com/bennpeifert/status/1453003455325421583?s=20">sql code</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
